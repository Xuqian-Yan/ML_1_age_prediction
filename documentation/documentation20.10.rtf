{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;\f1\fnil\fcharset0 Menlo-Bold;\f2\fnil\fcharset134 PingFangSC-Regular;
\f3\fnil\fcharset0 HelveticaNeue;\f4\fmodern\fcharset0 Courier;\f5\fnil\fcharset0 Menlo-Italic;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red0\green0\blue109;
\red0\green0\blue109;\red160\green0\blue163;\red128\green63\blue122;\red0\green0\blue254;\red109\green109\blue109;
\red82\green0\blue135;\red0\green0\blue0;\red255\green255\blue255;\red255\green255\blue0;}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;\csgenericrgb\c0\c0\c42745;
\csgenericrgb\c0\c0\c42745;\csgenericrgb\c62745\c0\c63922;\csgenericrgb\c50196\c24706\c47843;\csgenericrgb\c0\c0\c99608;\csgenericrgb\c42745\c42745\c42745;
\csgenericrgb\c32157\c0\c52941;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;\csgenericrgb\c100000\c100000\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \cb3 \CocoaLigature0 threshold =0 + random selection 3000 + standardise + kernel:\
smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 RandomSelection\
      
\f1\b \cf4 params:\
        random_state: 
\f0\b0 \cf0 37\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
    RandomSelection__n_components:\
      
\f0\b0 \cf0 - 3000\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 3\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171020-091106\
=
\f2 > MSE 641\
###############################\

\f0 smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs24 \cf0 \cb1 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 NonZeroSelection\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 RandomSelection\
      
\f1\b \cf4 params:\
        random_state: 
\f0\b0 \cf0 37\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
    RandomSelection__n_components:\
      
\f0\b0 \cf0 - 3000\
      - 5000\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 3\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf0 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171020-093021\
=> best: 5000, MSE 93\
############################\
smt run --model data/20171020-093021/GridSearchCV.pkl -X data/X_test.npy -a predict\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs24 \cf0 \cb1 \CocoaLigature1 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171020-093441\
=> score: 2900+?!\
##############################\
smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf5 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.pipeline\

\f1\b \cf5 class: 
\f0\b0 \cf0 Pipeline\

\f1\b \cf5 params:\
  class_list:\
    
\f0\b0 \cf0 - 
\f1\b \cf5 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf5 class: 
\f0\b0 \cf0 NonZeroSelection\
    - 
\f1\b \cf5 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf5 class: 
\f0\b0 \cf0 RandomSelection\
      
\f1\b \cf5 params:\
        n_components: 
\f0\b0 \cf0 3000\
        
\f1\b \cf5 random_state: 
\f0\b0 \cf0 37\
    - 
\f1\b \cf5 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf5 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf5 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf5 class: 
\f0\b0 \cf0 KernelEstimator\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171020-094307\
##############################\
smt run --model data/20171020-094307/Pipeline.pkl -X data/X_train.npy -y data/y_1.csv -a score\
\
20171020-095242\
=> ~10^(-20)\
##############################\
Standard answer:\
smt run --model data/20171020-094307/Pipeline.pkl -X data/X_test.npy -a predict
\fs24 \cf0 \cb1 \CocoaLigature1 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf0 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171020-095148\
=> MSE ~100\
###############################\
Standard answer, with random state 42:\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.pipeline\

\f1\b \cf4 class: 
\f0\b0 \cf0 Pipeline\

\f1\b \cf4 params:\
  class_list:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 NonZeroSelection\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 RandomSelection\
      
\f1\b \cf4 params:\
        n_components: 
\f0\b0 \cf0 3000\
        
\f1\b \cf4 random_state: 
\f0\b0 \cf0 42\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
#############################\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs24 \cf0 \cb1 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 NonZeroSelection\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 RandomSelection\
      
\f1\b \cf4 params:\
        n_components: 
\f0\b0 \cf0 3000\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
    RandomSelection__random_state:\
      
\f0\b0 \cf0 - 37\
      - 42\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 3\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf0 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171020-102016\
=
\f2 > 
\f3\fs26 \cf0 \cb1 \CocoaLigature1 negative mse
\f2 \'d3\'c3
\f3 37
\f2 \'ca\'c7
\f3 -105
\f2 \'a3\'ac
\f3  42
\f2 \'ca\'c7
\f3 -98\
###############################\
threshold 95%, standardise, PCA, kernel:\
\

\f0\fs22 \cf2 \cb3 \CocoaLigature0 smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\

\f3\fs26 \cf0 \cb1 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.decomposition\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 PCA\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
	PCA__n_components:\
		50,100,150
\f0\b0 \cf0 \
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 3\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171020-112521\
=>best n_components: 150, MSE 106\
############################\
Threshold 99%/ 99.9%, standardise, PCA 150, kernel:\
\
smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\

\f3\fs26 \cf0 \cb1 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.decomposition\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 PCA\
      
\f1\b \cf4 params:\
        n_components: 
\f0\b0 \cf0 150\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
    FeatureReduction__percentage:\
	- 80\
	- 85\
      
\f0\b0 \cf0 - 99\
      - 99.9\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 3\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f3\fs26 \cf0 \

\f0\fs22 \cf2 \cb3 \CocoaLigature0 20171020-115453\
=
\f2 > best threshold: 80%, MSE 100\
#################################\
threshold 80% + standardise + PCA 150 + lasso:\
\

\f0 smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.decomposition\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 PCA\
      
\f1\b \cf4 params:\
        n_components: 
\f0\b0 \cf0 150\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.linear_model\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 Lasso\
  
\f1\b \cf4 param_grid:\
    Lasso__alpha:\
      
\f0\b0 \cf0 - 0.5\
      - 1\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 3\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171020-122718\
=
\f2 > best alpha: 0.5, MSE 100 (not better than kernel)\
###############################\

\f0 smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 Hist\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
    Hist__bin:\
      
\f0\b0 \cf0 - 1000\
      - 3000\
      - 5000\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 3\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171020-130553\
=> best bins: 5000, MSE 104\
###########################\
smt run --config .config.yaml -X data/X_train.npy -a fit_transform\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 class 
\f0\b0 \cf0 LayerHist(BaseEstimator, TransformerMixin):\
    
\f1\b \cf4 def 
\f0\b0 \cf6 __init__ \cf0 (\cf7 self\cf0 , bins =\cf8 50\cf0 ):\
        \cf7 self\cf0 .bins =bins\
\
    
\f1\b \cf4 def 
\f0\b0 \cf0 fit(\cf7 self\cf0 , \cf9 X\cf0 , \cf9 y=None\cf0 ):\
        
\f1\b \cf4 return 
\f0\b0 \cf7 self\
\
    
\f1\b \cf4 def 
\f0\b0 \cf0 transform (\cf7 self\cf0 , X, \cf9 y=None\cf0 ):\
        X = check_array(X)\
        X_reshaped = np.reshape(X, (-\cf8 1\cf0 , \cf8 176\cf0 , \cf8 36608\cf0 ))\
        n = X_reshaped.shape[\cf8 0\cf0 ]\
        m = X_reshaped.shape[\cf8 1\cf0 ]\
        a = np.zeros((n, m*\cf7 self\cf0 .bins))\
        
\f1\b \cf4 for 
\f0\b0 \cf0 i 
\f1\b \cf4 in 
\f0\b0 \cf0 range(\cf8 0\cf0 , n):\
            
\f1\b \cf4 for 
\f0\b0 \cf0 j 
\f1\b \cf4 in 
\f0\b0 \cf0 range(\cf8 0\cf0 , m):\
                a[i, range(j * \cf8 50\cf0 , (j + \cf8 1\cf0 ) * \cf8 50\cf0 )] = np.histogram(X_reshaped[i, j, :], \cf10 bins\cf0 =\cf7 self\cf0 .bins, \cf10 range\cf0 =(\cf8 100\cf0 , \cf8 5000\cf0 ))[\cf8 0\cf0 ]\
        
\f1\b \cf4 return 
\f0\b0 \cf0 a\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 \
20171021-000632\
=> 
\f4\fs28 \cf11 \cb12 \expnd0\expndtw0\kerning0
\CocoaLigature1 \outl0\strokewidth0 \strokec11 (278, 8800)\
#######################\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
    LayerHist__bins:\
 
\f5\i\b0 \cf9 #     - 500\
#      - 800\
      
\f0\i0 \cf0 - 1000\

\f5\i \cf9 #      - 1300\
  
\f1\i0\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 3\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-003234\
fit: best 1000, MSE 70\
\
smt run \'97model data/20171021-005655/GridSearchCV.pkl -X data/X_test.npy -a predict\
=> 20171021-010127\
=> many negatives ({\field{\*\fldinst{HYPERLINK "https://piazza.com/class/j66804egrys7h2?cid=219"}}{\fldrslt https://piazza.com/class/j66804egrys7h2?cid=219}}, bug of grid search CV)\
########################################
\fs24 \cf0 \cb1 \CocoaLigature1 \

\fs22 \cf2 \cb3 \CocoaLigature0 smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs24 \cf0 \cb1 \CocoaLigature1 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.pipeline\

\f1\b \cf4 class: 
\f0\b0 \cf0 Pipeline\

\f1\b \cf4 params:\
  class_list:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
      
\f1\b \cf4 params:\
        bins: 
\f0\b0 \cf0 1000\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-011324\
#######################################\
smt run --model data/20171021-011324/Pipeline.pkl -X data/X_test.npy -a predict\
\
20171021-011545\
\cb13 => MSE online 98\cb3 \
=>because \'91pipeline\'92 uses all data, which leads to overfit; which gridsearchCV only uses 2/3 data.\
###################################\
with 8-fold CV:\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs24 \cf0 \cb1 \CocoaLigature1 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
    LayerHist__bins:\
      
\f0\b0 \cf0 - 500\
      - 1000\
      - 1500\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 8\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-082229\
=> best bins: 1000, MSE:66\
#################################\
smt run --model data/20171021-082229/GridSearchCV.pkl -X data/X_test.npy -a predict\
\
20171021-085501\
=> exactly same as before changing CV method\
#################################\
ridge:\
smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
      
\f1\b \cf4 params:\
        bins: 
\f0\b0 \cf0 1000\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
  
\f1\b \cf4 param_grid:\
    Ridge__alpha:\
      
\f0\b0 \cf0 - 0.3\
      - 0.5\
      - 1\
\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 8\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 \
20171021-090134\
=> best: 0.3, MSE 66 (not better than kernel)\
###########################\
Lasso:\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
      
\f1\b \cf4 params:\
        bins: 
\f0\b0 \cf0 1000\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.linear_model\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 Lasso\
  
\f1\b \cf4 param_grid:\
    Lasso__alpha:\
      
\f0\b0 \cf0 - 0.3\
      - 0.5\
      - 1\
\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 8\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-092234
\fs24 \cf0 \cb1 \CocoaLigature1 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf0 =>best: 0.3, MSE 76 (worse than ridge)\
################################\
with only pipeline:\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs24 \cf0 \cb1 \CocoaLigature1 \

\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.pipeline\

\f1\b \cf4 class: 
\f0\b0 \cf0 Pipeline\

\f1\b \cf4 params:\
  class_list:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
      
\f1\b \cf4 params:\
        bins: 
\f0\b0 \cf0 1000\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.linear_model\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 Ridge\
      
\f1\b \cf4 params:\
        alpha: 
\f0\b0 \cf0 0.3\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-095126\
\
smt run --model data/20171021-095126/Pipeline.pkl -X data/X_test.npy -a predict\
\
20171021-095340\
=> almost the same as kernel\
###########################\
block histogram: every layer * 16 (in total 8 layers) + kernel:\
\
smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
    LayerHist__bins:\
      
\f0\b0 \cf0 - 500\
      - 1000\
      - 1500
\f2 , 2000, 3000, 5000
\f0 \
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 5\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-112105\
=> best: 5000, MSE 82\
###########################\
block hist (5000 bin) + bayesian ridge:\
smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\

\fs24 \cf0 \cb1 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.linear_model\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 BayesianRidge\
  
\f1\b \cf4 param_grid:\
    LayerHist__bins:\
      
\f0\b0 \cf0 - 5000\
\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 5\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf0 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-114121\
=>best bins: 8000, MSE 80\
##########################\
smt run --config .config.yaml -X data/X_train.npy -a fit_transform\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 class 
\f0\b0 \cf0 LayerHist(BaseEstimator, TransformerMixin):\
    
\f1\b \cf4 def 
\f0\b0 \cf6 __init__ \cf0 (\cf7 self\cf0 , bins =\cf8 50\cf0 ):\
        \cf7 self\cf0 .bins =bins\
\
    
\f1\b \cf4 def 
\f0\b0 \cf0 fit(\cf7 self\cf0 , \cf9 X\cf0 , \cf9 y=None\cf0 ):\
        
\f1\b \cf4 return 
\f0\b0 \cf7 self\
\
    
\f1\b \cf4 def 
\f0\b0 \cf0 transform (\cf7 self\cf0 , X, \cf9 y=None\cf0 ):\
    X = check_array(X)\
    X_reshaped = np.reshape(X, (-\cf8 1\cf0 , \cf8 176\cf0 , \cf8 208\cf0 ,\cf8 176\cf0 ))\
    n = X_reshaped.shape[\cf8 0\cf0 ]\
    
\f5\i \cf9 #m = X_reshaped.shape[1]\
    
\f0\i0 \cf0 a = np.zeros((n, \cf8 8\cf0 *\cf8 8\cf0 *\cf7 self\cf0 .bins))\
    b = np.zeros((\cf8 8\cf0 , \cf8 8\cf0 *\cf7 self\cf0 .bins))\
    
\f1\b \cf4 for 
\f0\b0 \cf0 i 
\f1\b \cf4 in 
\f0\b0 \cf0 range(\cf8 0\cf0 , n):\
        
\f1\b \cf4 for 
\f0\b0 \cf0 j 
\f1\b \cf4 in 
\f0\b0 \cf0 range(\cf8 0\cf0 , \cf8 8\cf0 ):  
\f5\i \cf9 # 176 =8 *22\
            
\f1\i0\b \cf4 for 
\f0\b0 \cf0 k 
\f1\b \cf4 in 
\f0\b0 \cf0 range(\cf8 0\cf0 , \cf8 8\cf0 ):  
\f5\i \cf9 # 208 = 8 * 26\
                
\f0\i0 \cf0 b[j, range(k * \cf7 self\cf0 .bins, (k + \cf8 1\cf0 ) * \cf7 self\cf0 .bins)] = \\\
                np.histogram(X_reshaped[i, (j * \cf8 22\cf0 ):((j + \cf8 1\cf0 ) * \cf8 22\cf0 ), (k * \cf8 26\cf0 ):((k + \cf8 1\cf0 ) * \cf8 26\cf0 ), :], \cf10 bins\cf0 =\cf7 self\cf0 .bins,\
                             \cf10 range\cf0 =(\cf8 100\cf0 , \cf8 5000\cf0 ))[\cf8 0\cf0 ]\
\
        a[i, :] = np.reshape(b, (\cf8 1\cf0 , -\cf8 1\cf0 ))\

\f5\i \cf9         
\f1\i0\b \cf4 return 
\f0\b0 \cf0 a\
\
###########################\
strip blocks hist + kernel:\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.regression\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 KernelEstimator\
  
\f1\b \cf4 param_grid:\
    LayerHist__bins:\
      
\f0\b0 \cf0 - 500\
      - 1000\
      - 1500\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 5\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-130312\
=> best bins: 1000, \cb13 MSE 66\cb3 \
############################\
strip hist (1000 bins) + ridge:\
\
smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.model_selection\

\f1\b \cf4 class: 
\f0\b0 \cf0 GridSearchCV\

\f1\b \cf4 params:\
  est_module: 
\f0\b0 \cf0 ml_project.pipeline\
  
\f1\b \cf4 est_class: 
\f0\b0 \cf0 Pipeline\
  
\f1\b \cf4 est_params:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
      
\f1\b \cf4 params:\
        bins: 
\f0\b0 \cf0 1000\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.linear_model\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 Ridge\
  
\f1\b \cf4 param_grid:\
    Ridge__alpha:\
      
\f0\b0 \cf0 - 0.3\
      - 0.5\
      - 1\
  
\f1\b \cf4 scoring: 
\f0\b0 \cf0 neg_mean_squared_error\
  
\f1\b \cf4 cv:\
    module: 
\f0\b0 \cf0 sklearn.model_selection\
    
\f1\b \cf4 class: 
\f0\b0 \cf0 KFold\
    
\f1\b \cf4 params:\
      n_splits: 
\f0\b0 \cf0 5\
      
\f1\b \cf4 shuffle: 
\f0\b0 \cf0 True\
      
\f1\b \cf4 random_state: 
\f0\b0 \cf0 37\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-131654\
=> best alpha: 1, MSE 65 (not better than kernel)\
###########################\
smt run --config .config.yaml -X data/X_train.npy -y data/y_1.csv -a fit\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs24 \cf4 \cb1 \CocoaLigature1 module: 
\f0\b0 \cf0 ml_project.pipeline\

\f1\b \cf4 class: 
\f0\b0 \cf0 Pipeline\

\f1\b \cf4 params:\
  class_list:\
    
\f0\b0 \cf0 - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.feature_selection\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 LayerHist\
      
\f1\b \cf4 params:\
        bins: 
\f0\b0 \cf0 1000\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 ml_project.models.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 FeatureReduction\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.preprocessing\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 StandardScaler\
    - 
\f1\b \cf4 module: 
\f0\b0 \cf0 sklearn.linear_model\
      
\f1\b \cf4 class: 
\f0\b0 \cf0 Ridge\
      
\f1\b \cf4 params:\
        alpha: 
\f0\b0 \cf0 1\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 20171021-134007\
\
smt run --model data/20171021-134007/Pipeline.pkl -X data/X_test.npy -a predict\
20171021-134242\
\cb13 =
\f2 > MSE online: 70\cb3 \
######################################
\f0 \
\
}